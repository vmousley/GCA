---
title: 'Phase 3 Pop-out: Report on Developmental Trend'
author: "Teresa Del Bianco"
date: "29/11/2019"
output:
  word_document: default
  html_document:
    toc: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r, include = FALSE}
# Load packages
packs <- c("dplyr", "ggplot2", "knitr", "tidyr", "reshape2", "ggpubr")
lapply(packs, require, character.only = TRUE)
```

```{r, include=FALSE}
load("SavedWS/data-aggr-0-5.RData")
load("SavedWS/NA_info.RData")
load("SavedWS/raw-plots.RData")
load("SavedWS/sel-model.RData")
load("SavedWS/tb_plots.RData")
load("SavedWS/errs.RData")
load("SavedWS/gender.RData")
load("SavedWS/traj.RData")
```

# Sample and descriptive outline

## Sample Size

Report total sample size, sample size by visit.

The current data consists of `r length(unique(data.aggr.0.5$id))` participants; the participants contributed at various time-points as reported in the Table 1 and 2. 

```{r, Table 1}
ss <- data.aggr.0.5 %>%
  distinct(id, age) %>%
  group_by(age) %>%
  summarise(N=length(unique(id)))
kable(ss, caption = "Table 1: Initial sample size per timepoint")
```
<br>
```{r}
n_vis <- data.aggr.0.5 %>%
  group_by(id) %>%
  summarise(g=length(unique(as.factor(age)))) %>%
  group_by(g) %>%
  summarise(N=n()) %>%
  rename('N of Visits'=g)
kable(n_vis, caption = "Table 2:N of participants that participanted to 1-5 number of visits at timepoints from 5 to 36 months")
```

## Retired participants

`r length(unique(id_x$id))` participants dropped out from the study and were therefore excluded from the analysis, with a final sample size of `r length(unique(data.aggr.0.5.rg.fin$id))` infants, of whom `r length(unique(subset(data.aggr.0.5.rg.fin, ASD=="1")$id))` with 1 sibling with ASD/ADHD (high likelihood group). 

The data presented hereafter was taken from 500 ms after stimulus onset until 5 seconds (end of trial). 

## Missing Data

Report percentage of missing data per trial, exclusion criteria and number of excluded participant plus final sample size and data quality per visit
<br>
```{r}
pNA_ag <- p_NA %>%
  group_by(age) %>%
  summarise('Mean %'=round(mean(pNA, na.rm=TRUE), 2),
            'SD'=round(sd(pNA, na.rm=TRUE),2),
            '75% P'=round(quantile(pNA, prob=0.75),2),
            '25% P'=round(quantile(pNA, prob=0.25),2))
kable(pNA_ag, caption = "Table 3: Average percentage of missing data, standard deviation, upper and lower quartile per age group across trials for the whole sample")
```
<br>
```{r}
final_ss <- data.aggr.0.5.rg.clean %>%
  distinct(id, age) %>%
  group_by(age) %>%
  summarise(N=length(unique(id)))
kable(final_ss, caption = "Table 4: Final sample size per timepoint after the exclusion of participants with 100% of trials with percentage of missing data > 25%")
```

The final sample size consisted of `r length(unique(data.aggr.0.5.rg.clean$id))`, of whom `r length(unique(subset(data.aggr.0.5.rg.clean, ASD=="1")$id))` with familiar risk of ASD

```{r}
pNA_final_ag <- p_NA %>%
  filter(pNA<=25) %>%
  group_by(age) %>%
  summarise('Mean %'=round(mean(pNA, na.rm=TRUE), 2),
            'SD'=round(sd(pNA, na.rm=TRUE),2),
            '75% P'=round(quantile(pNA, prob=0.75),2),
            '25% P'=round(quantile(pNA, prob=0.25),2))
kable(pNA_final_ag, caption = "Table 5: Average percentage of missing data, standard deviation, upper and lower quartile per age group across trials for the final clean sample")
```

## Non-looking trials

Report percentage of non-looking trials and number of excluded participants (if any)

```{r, fig.align="center", fig.width=12, dpi=300, fig.cap="Figure 1: Average Percentage of Non-Looking Trials per participants across trials"}
nL.trials %>%
  group_by(id, age) %>%
  summarise(perc.mL=mean(perc.mL, na.rm=TRUE)) %>%
  ggplot() +
  geom_histogram(aes(x=reorder(id, age), y=perc.mL,
                   fill=factor(age)), 
               color="black",
               stat = "identity",
               position = "identity") +
  theme_bw() +
  ylim(0,4.5) + 
  theme(axis.text.x = element_blank()) +
  labs(y="% of Non-looking Trials",
       x="Participant",
       fill="Age (months)") 
```

## Descriptive statistics

Report fundamental sample characteristics

```{r}
r_g <- data.aggr.0.5.rg.clean %>%
  as.data.frame() %>%
  distinct(id, age, sex, ASD, ADHD) %>%
  group_by(age) %>%
  summarise(N.FEM=sum(sex=="F", na.rm=TRUE),
            N.HL.ASD=sum(ASD=="1" & ADHD=="0", na.rm=TRUE),
            N.HL.ADHD=sum(ASD=="0" & ADHD=="1", na.rm=TRUE),
            N.HL.ASD.ADHD=sum(ASD=="1" & ADHD=="1", na.rm=TRUE),
            N.LL=sum(ASD=="0" & ADHD=="0", na.rm=TRUE),
            N.NA=sum(is.na(ASD)),
            "N TOT"=N.HL.ASD+N.HL.ADHD+N.HL.ASD.ADHD+N.LL+N.NA
            ) %>%
  rename("N H-L ASD"=N.HL.ASD,
         "N H-L ADHD"=N.HL.ADHD,
         "N H-L ASD & ADHD"=N.HL.ASD.ADHD,
         "N L-L"=N.LL,
         "N NA"=N.NA)
```

```{r}
kable(r_g, caption = "Table 5: number of participants pertaining to the different likelihood groups (high-likelihood of ASD (H-L ASD), ADHD (H-L ADHD), both (H-L ASD & ADHD), low-likelihood (L-L), not available (NA))")
```

## Raw data plots

### Average proportional looking time

```{r, fig.align="center", fig.width = 10, fig.height = 8.5, dpi=300, fig.cap="Figure 3: Boxplots of the average Proportional Looking Time by age collapsed on time across the trial"}
all.avg.plt
```

### Time-series of proportional looking time

```{r, fig.align="center", fig.width = 10, fig.height = 8.5, dpi=300, fig.cap="Figure 4: Average Proportional Looking Time by age and time in the trial with 95% confidence intervals"}
all.ts.plt
```

# Analysis

We aggregated the cleaned data in time bins of 0.5 second and further analysed the proportional looking time data towards the face and the car. 

The visual inspection of the proportional-looking time across the duration of the trial suggested a curvature in the rate of change across time; therefore, we decided to include orthogonal polynomials as fixed and random predictors in a multilevel regression model. Additionally, we included age in the model as continuous, fixed predictor; since the measurements are repeated within participants, we included random intercept and slope per participant in the model. 

Adding polynomials to the model means adding the value of time raised to the nth power; in this case, we calculated the “orthogonal” – or transformed – polynomials, to avoid intercorrelation between the values. These polynomials help to fit the model to the actual shape of the data, since they describe various curvilinear profiles, as shown in Figure 3 and 4.

Since an increasing polynomial order tend to increase the fit to the data, we planned to select the best fit curve based on meaningful considerations. In this case, when we examine the proportional looking time to one AOI, we may expect at least 1 peak in the probability distribution, described, in polynomials term, as a roughly symmetrical rise and fall – configured by the quadratic polynomial. This configuration may represent a typical response to the experimental design, where the participant’s attention alternates between a target and numerous distractors. 
Nonetheless, the current design may also allow to go back and forth between target and distractors, therefore, we may expect an asymmetrical peak with 3 changes of focus – from target to distractor, and back to target (even though, in the raw data, we only observe single peaks). 

```{r}
pos <- data.aggr.0.5.rg.clean %>%
  group_by(block.05) %>%
  distinct(ot1, ot2, ot3) %>%
  as.data.frame() %>%
  melt(id.vars="block.05") %>%
  mutate(block.05=block.05/2,
         value.2=-value) %>%
  ggplot(aes(x=block.05, y=value, color=variable)) +
  geom_path() +
  labs(x="Time (s)", y="", col="Poly", caption="positive coefficient") +
  theme_bw()
neg <- data.aggr.0.5.rg.clean %>%
  group_by(block.05) %>%
  distinct(ot1, ot2, ot3) %>%
  as.data.frame() %>%
  melt(id.vars="block.05") %>%
  mutate(block.05=block.05/2,
         value.2=-value) %>%
  ggplot(aes(x=block.05, y=value.2, color=variable)) +
  geom_path() +
  labs(x="Time (s)", y="", col="Poly", caption="negative coefficient") +
  theme_bw()
```

```{r, dpi=300, fig.width=10, fig.cap="Figure 5: sample curves representing polynomial orders up to degree 3"}
ggarrange(pos, neg, common.legend = TRUE)
```

For the selection of the polynomial order, we split the dataset into a train and test set (respectively, 75% and 25% of the data). We compared the Root Squared Mean Error (RSME) of the model fit to the train and the test data. After selecting the model with the lowest RSME, we tested the contribution of the image display as random intercept, and age as a fixed predictor with the Likelihood Ratio Test (LRT).

In a second round of selection, we restricted the dataset to infants with likelihood information and we tested the contribution of 1) sex 2) high likelihood of atypical neuro-development (ASD) 3) high likelihood of ADHD (covariate)

After selecting the model with the best fit, we calculated the p-values of the beta coefficients with multiple t-tests using Satterthwaite's approximation method. We calculated the 95% confidence intervals of the beta coefficients with the Wald approximation method, and we tested the individuals contrasts with type III Analysis of Variance. 

To further compensate the approximation used for the calculation of p-value and confidence interval, we calculated a prediction interval for each individual age group, including the variation embedded in the fixed effects and the residuals, as well as the conditional modes of the random effects. The prediction interval is illustrated in Figure 5. 
Finally, we examined the relationship between the individual coefficients, the individual standard errors and the number of data points – and its potential impact on the estimation of the beta coefficients. 

# Results

## Model Selection

### Face

We obtained a smaller RSME by adding orthogonal polynomials up to degree 3 with the training set. The model with 3rd degree polynomials with the test set did not obatin a bigger RSME (Table 6).

```{r}
rsme <- data.frame(Polynomial.Order=c("-", "2nd", "3rd"),
                   Train.Set=round(train.mse, 4),
                   Test.Set=c(NA, NA, round(test_mse, 4)))
rownames(rsme) <- NULL
kable(rsme, col.names = c("Polynomial Order", "Train Set", "Test Set"), caption = "Table 6: RSME calculated for each model, respectively with the test and training sets.")
```

The LRT revealed the model including age as fixed predictor as the best fit model (see Table 7). 
The Chi-Squared degrees of freedom show that this model contains 5 more levels than the base model, as Age contains 5 levels of variation (5, 10, 14, 24 and 36 months). The two models are considerably different from each other and the second model shows a strikingly better fit – which is already a demonstration that Age plays a role in determining the proportional looking time at the face in this setting. All the relevant indicators of the fit of the model (AIC, BIC and logLik) significantly decrease when age is added, showing that this model significantly contributes to explain the variance in the data.

```{r}
kable(m.anv.age, caption = "Table 7: LRT between the base model of 3rd polynomial order (no fixed effect), and the model including age as a fixed predictor")
```

#### Gender and Likelihood Group

A model with Gender in interaction with Age presented an improvement of the fit:

```{r}
kable(m.anv.sex, caption = "Table 9: xxx")
```

Also, after adding sex in interaction with age, the likelihood group turned out to marginally improve the fit of the model:

```{r}
kable(m.anv.rg.tidy, caption = "Table 10: xxx")
```

Finally, the model including likelihood of ASD in interaction with age, and ADHD as covariate, obtained the best fit:

```{r}
kable(m.anv.rg.full.tidy, caption = "Table 11: xxx")
```

### Car

For the AOI car, we adopted a polynomial order of degree 2 by comparing RSMEs across order and the train and the test set (see Table 9). The RSME of the test set increased, suggesting that a 3rd degree polynomial order was overfitting the data. 

```{r}
rsme_car <- data.frame(Polynomial.Order=c("-", "2nd", "3rd"),
                       Train.Set=round(c_rsme_train, 4),
                       Test.Set=c(NA, NA, round(c_rsme_test, 4)))
rownames(rsme) <- NULL
kable(rsme_car, col.names = c("Polynomial Order", "Train Set", "Test Set"), caption = "Table 12: RSME calculated for each model, respectively with the test and training sets.")
```

The model including age as a fixed predictor fitted best to the whole dataset. Furthermore, the model including the interaction between age and likelihood group fitted best the dataset including the infants with likelihood information (see Table 10 and 11). 

```{r}
kable(mc.anv.age.tidy, caption = "Table 13: LRT of the best fit model vs the models including age")
```

```{r}
kable(mc.anv.rg.tidy, caption = "Tabel 14: LRT of the best fit model vs the models including Likelihood group for ASD")
```

## Fixed Effects

### Face

Table 12 shows the beta coefficients of all the predictors contained in the model. The intercept corresponds to the average height of the curve across the trial, or the average probability for the infants to hit the face irrespective of other predictors. The intercepts stands significantly above the chance level (i.e., the possibility of hitting on the AOI face by chance, corresponding to 1/the number of AOIs, 5). Also, we observe a significant decrease of this value across the trial (i.e., negative slope), irrespective of age. With age, the average height of the curve tend to decrease. 
The effect of age on the 2nd and 3rd degree polynomials is significant: they respectively tend to become more positive and more negative. A more positive quadratic term with age indicates an increasingly steep decrease of face looking time across the trail with age; a more negative cubic term indicates a higher tendency to peak post-decrease (see the turquoise curve on the right in figure 5). 
Figure 6 easily illustrate this trend, where the stable preference for the face seems to rapidly decrease over the course of the trial with age.

```{r}
kable(est_face, caption = "Table 15: Estimates of fixed effects predicting the proportional looking time to the face, with the 95% confidence intervals")
```

```{r, fig.width=9, fig.height=7, dpi=300, fig.align="center", fig.cap="Figure 6: fitted curve of the model with the prediction interval for each age group"}
g_face
```

#### Effect of Gender and Likelihood Group

Gender modulated the effect of age and of ot1. Males and females of different likelihood risks show different developmental trajectories: 

```{r}
kable(est_face_sex, caption = "Table 15: Estimates of fixed effects predicting the proportional looking time to the face, with the 95% confidence intervals")
```
<br>
```{r}
kable(est_face_sex_rg, caption = "Table 16: Estimates of fixed effects predicting the proportional looking time to the face, with the 95% confidence intervals")
```

```{r, fig.width=9, fig.height=7, dpi=300, fig.align="center", fig.cap="Figure 7: fitted curve of the model with the prediction interval for each age group by group and sex"}
g_face_sex_rg
```

### Car

This models shows that the proportional looking time to the car tends to increase with age with a S-shaped profile (defined by the term ot3). Notably, infants with high-likelihood of ASD show a higher increase of the average looking time with age (age:ASD1). The trend is shown in Figure 7. 

```{r}
kable(est_car, caption = "Table 17: Estimates of fixed effects predicting the proportional looking time to the car, with the 95% confidence intervals")
```

```{r, fig.width=9, fig.height=7, dpi=300, fig.align="center", fig.cap="Figure 7: fitted curve of the model with the prediction interval for each age group"}
g_car_rg
```

# Individual Scores and Standard Errors

Let us consider the reliability of the coefficients reported in the previous section. In a mixed model, the coefficients constitute an average of the individual coefficients, whose deviation is estimated by the random effect. The model considers the reliability of the individual coefficient too, and weights it when including it in the coefficient calculation. The weight is highly dependent on the number of observations available for the individual - less observation, less reliability, less weight. 

In the below plot, we visualise the individual coefficients, corresponding to the sum of the fixed effect and the individual variance component (as specified in the random effect). The error bars represent the standard errors, calculated as the the joint MSE of the summated variances of the fixed and the random effect. The  plot nicely illustrates how standard errors of the individual coefficients of the proportional looking time to the face increases for participants with fewer observations. In this model, we observe at least 50% of individual coefficient with a standard error above the average standard error. 

In a standard multiple regression model, all the observations would be weighted equally, with no consideration for the reliability of the estimate given, for instance, the number of observations. The mixed model instead contains a measure of the error of individual coefficients, thus, the final estimate is less influenced by extreme observations with a substantial error. 

Another factor to take into account is the complexity of the model; a more complex model, while it reduces the bias due to the assumptions of a certain function, it substantially increases the variance of the model. In other words, the model reacts to small fluctuations in the data and may be prone to overfitting, even to the observations with the red bar. Therefore, the conclusions of such a model must be taken with care. The precision of this model may be improved by adding a validation set.

```{r, fig.align="center", fig.width=9, fig.height=12, dpi=300, fig.cap="Fig. 9: Individual estimates and standard errors of the Intercept for the proportional looking time to the face and the car, on the numerosity of the observations per infant. The horizontal lines represent the average Intercept estimate + 95% CI"}
comp_n_mm_comp
```


